\section{Introduction}
\label{intro}

\newcommand\ForLine[1]{\State\algorithmicfor１茚扃矧轸桧殂滹
\newcommand\Head[1]{\Comment{ {\it #1} ~}}

Software synthesis aims to close the gap between descriptions of software components, such as algorithms and systems, and their implementations as computer programs. Dynamic Programming (DP) algorithms offer a prominent example of how large this gap can be. For instance, consider  
\cbstart\diffnote{some short explanation, and link}%
\Cref{intro:naive}, which correspond to the well known DP algorithm to compute the optimal parenthesization for a chain of matrix multiplications.\footnote{\fontsize{6}{6}\selectfont\url{https://en.wikipedia.org/wiki/Matrix_chain_multiplication}}
The first loop fills the diagonal of an array with some initial values,
and the second loop computes off-diagonal elements by reading existing elements.
\cbend

The algorithm computes an $n\times n$ region of a DP table $G$ via a standard row-major order. This algorithm is simple, but a direct C implementation of it turns out to be about
$10\times$ slower than the best manually optimized implementation \cbstart(as we will see in \Cref{evaluation:experimental})\cbend. 
One reason for this poor performance is the high rate of cache misses incurred by reading the ranges $G_{ik}$ and $G_{kj}$, for $i<k<j$, repeatedly on every iteration of the loops over $i$ and $j$. Memory reads dominate the running time of this algorithm, so high speedups can be gained by localizing memory access.

\begin{algorithm}[b]
\renewcommand\arraystretch{1.3}
\begin{algorithmic}
  \ForLine{$i=1..n$}  $G_{i(i+1)} := x_i$    \Head{Initialize}
  \For{$i=(n-2)..0$}          \Head{Compute}
    \For{$j=(i+2)..n$}
      \State $G_{ij} := \underset{i<k<j}\min  G_{ik} + G_{kj} + w_{ikj}$
    \EndFor
  \EndFor
\end{algorithmic}
\caption{\label{intro:naive}
   A na\"ive loop implementation}
\end{algorithm}


The state-of-the-art implementation uses a \newterm{divide and conquer} approach both to improve memory performance and to increase the asymptotic degree of parallelism\cite{IPDPS15/Tithi}. An excerpt of the pseudo-code for such an implementation is shown in \Cref{intro:divide-and-conquer}. In the optimized version, the programmer has to determine a number of low-level details, including the correct order of calls---some of which can be run in parallel---as well as some rather involved index arithmetic. When implemented in C++, the full version is, in fact, more than ten times longer than the na\"ive one and considerably more complicated. It is also much more difficult to verify, since the programmer would have to provide invariants and contracts for a much larger set of loops and possibly recursive functions. Parallelism only adds to the complexity of this task.



\begin{algorithm}[b!]
\fontsize{9}{10}   % being sneaky!
\begin{algorithmic}
  \State A[$1..n$], where: \hfill{\normalsize (\textit{snippet})}
  \Procedure{A{\larger{[}}$s..e${\larger{]}}}{}
	\If{$e-s < b$}
	  \For{$i=e..s$}
	    \For{$j=\max\{s,i\}..e$}
	      \State $G_{ij} := \underset{i<k<j}\min  G_{ik} + G_{kj} + w_{ikj}$
	    \EndFor
	  \EndFor
    \vspace{-5pt}
	\Else
	  \State A$\big[ s..\floor{\frac{s+e}{2}} \big]$
	  \State A$\big[ \floor{\frac{s+e}{2}}{+}1..e \big]$
	  \State B$\big[ s..\floor{\frac{s+e}{2}} , \floor{\frac{s+e}{2}}{+}1..e \big]$
	\EndIf
  \EndProcedure
  \Procedure{B{\larger{[}}$s_0..e_0 , s_1..e_1${\larger{]}}}{}
	\If{$e-s < b$} \ldots
	\Else
	  \State B$\big[ \floor{\frac{s_0+e_0}{2}}{+}1..e_0 , s_1..\floor{\frac{s_1+e_1}{2}} \big]$
	  \State C$\big[ s_0..\floor{\frac{s_0+e_0}{2}} , s_1..\floor{\frac{s_1+e_1}{2}} , \floor{\frac{s_1+e_1}{2}}{+}1..e_1 \big]$
	  \vspace{-5pt}
	  \State $\vdotswithin{C}$
	\EndIf
  \EndProcedure
  \Procedure{C{\larger{[}}$s_0..e_0 , s_1..e_1 , s_2..e_2${\larger{]}}}{}
    \vspace{-5pt}
    \State $\vdots$
  \EndProcedure
\end{algorithmic}
\caption{\label{intro:divide-and-conquer}
   An optimized divide-and-conquer version}
\end{algorithm}




In this paper, we present a new system called Bellmania\footnote{Named so as a tribute to Richard Bellman.}, which allows an expert to interactively generate parallel divide-and-conquer implementations of dynamic programming algorithms, which are provably correct relative to a high-level specification of the code in \Cref{intro:naive}. We show that the resulting implementations are \cbstart\diffnote{use ranges}1.4--46$\times$ faster than the original versions and within 2--60\%\cbend{} of a high-performance hand crafted implementation.
Their structure will also make them \newterm{cache oblivious}\cite{FOCS99/Frigo} and \newterm{cache adaptive}\cite{SODA14/Bender}, just like the hand crafted implementations are.


Bellmania is a deductive synthesis system in the tradition of systems like KIDS\cite{TSE90/Smith}, and more recently Fiat\cite{POPL15/Delaware}. 
These systems derive an implementation from a specification in a correct-by-construction manner by applying a sequence of deductive reasoning steps. Thanks to the correct-by-construction approach, the potentially complex final artifact does not have to be independently verified, making the approach ideal for potentially complex implementations like the ones we target. 

Traditionally, the major shortcoming of deductive synthesis has been the effort required of the user in order to guide the derivation process towards a correct solution. In this work, we reduce this effort using three core techniques. 
First, we show that a small number of domain specific tactics, combined with a new notation to jointly describe the specification and the implementation, can enable the derivation to be described succinctly at a high-level of abstraction. Secondly, we show the value of incorporating an SMT solver into the derivation process; in particular, we can afford to use tactics that are only correct when some side conditions hold, where these conditions are potentially complex logical assertions, without having to burden the user with proving those premises. Finally, we show that by incorporating \emph{solver-based inductive synthesis},
which generalizes from concrete values and execution traces, into the derivation process, we can automate away many low-level decisions, allowing for shorter, simpler derivations. We use the term \emph{solver-aided tactics} to refer to this combination of solver-based inductive synthesis and solver-checked premises within a tactic.

Overall, the paper makes the following contributions. 
\begin{itemize}
\item A new formalism used to describe a wide class of dynamic programming algorithms, capable of bridging the gap between the high-level specification and the divide-and-conquer implementation of them.

\item An interesting application of refinement types for tracking dependencies between sub-computations, making it possible to automatically generate parallel implementations from it.

\item The idea of using \emph{solver-aided tactics}, demonstrating their applicability and utility in the derivation of divide-and-conquer dynamic programming implementations. 

\item A suite of solver-aided tactics for dynamic programming and an overview of the proofs of their soundness, assuming only the soundness of the underlying SMT solver. 

\item A description of Bellmania, the first system capable of generating provably correct implementations of di\-vide-and-conquer dynamic programming. Our evaluation shows that the code it generates is comparable to manually tuned implementations written by experts in terms of performance.
\end{itemize}

Dynamic Programming is central to many important domains ranging from logistics to computational biology --- e.g.,a recent textbook \cite{DurbinEdKr98} lists 11 applications of DP in bioinformatics just in its introductory chapter, with many more in chapters that follow. Increasing performance and reliability of DP implementations can therefore have significant impact. More generally, we believe that this work serves as an important test case for a new approach to combining inductive and deductive synthesis which could have an impact beyond this domain. 



%==============================================



%In this paper, we present a new approach to interactive deductive synthesis based on \emph{solver-aided tactics} that preserves the benefits of deductive synthesis techniques but reduces the burden on the user by relying on two important innovations: (a) the use of inductive synthesis to discover important details of the low-level steps needed to achieve a transformation, (b) the use of a type system based on predicate abstraction (liquid types) that associates semantic information with program terms, enabling automated verification of the validity of a transformation. Both of these innovations rely on extensive use of SMT solvers to discharge complex proof obligations that would otherwise have to be discharged interactively with significant manual effort. 


\begin{comment}


Our work on solver-aided tactics builds on prior work on the StreamBit project\cite{PLDI05/Solar-Lezama}, which
introduced the idea of transformation rules with missing details that can be inferred by a symbolic search procedure, as
well as the pioneering work on the Leon synthesizer\coa{cite?}, which has explored the integration of deductive techniques to improve the
scalability of inductive synthesis. However, our approach is unique in the way it leverages inductive synthesis and
typing in the context of deductive synthesis: 
(a) the solver can use inductive synthesis to search for the detailed parameters required for a transformation,
(b) The solver can prove validity of side conditions that ensure the soundness of each individual transformation, 
(c) the tactics can leverage information from \newterm{logically qualified types} in the program in
    order to guide the transformation. 
Being able to rely on the solver to check the validity of transformations gives greater flexibility when designing such transformations. 
It means that we do not have to be conservative when stating preconditions.
In addition, the reliance on the synthesizer to fill in parameters and proof details means that the user has to type less and has fewer chances to make mistakes.

Overall, we make the following contributions.
\begin{itemize}
\item We introduce \emph{solver-aided tactics}, a form of rewrite rules with proof obligations that can be translated to first-order logic,
  as a way to raise the level of abstraction of deductive synthesis.
\item We develop a small library of these formal tactics that can be used to 
  systematically transform a class of problem specifications,
  expressed as recurrences in a simple functional language,
  into equivalent divide-and-conquer programs that admit cache-oblivious parallel
  implementations.
\item We prove that these tactics are semantics-preserving, assuming some side conditions are met
  at the point when the tactic is applied.
\item We show that the side conditions can be effectively translated into first-order closed
  formulas, and verified automatically by SMT solvers.
\item We demonstrate the first system capable of generating provably correct implementations of divide-and-conquer implementations from a high-level description of the algorithm. 
\item We measure the performance of automatically generated code and show that it is comparable to manually tuned reference implementations written by experts.
\end{itemize}


\end{comment}


%We believe the approach has the potential to be generally applicable to a variety of synthesis problems, but in this paper, we focus on a particular domain of \emph{divide-and-conquer dynamic programming} algorithms. Specifically, we have developed a system called \emph{Bellmania} that uses solver-aided tactics specialized for this domain to help an algorithm designer derive divide-and-conquer dynamic programming algorithms from a high-level specification. 

